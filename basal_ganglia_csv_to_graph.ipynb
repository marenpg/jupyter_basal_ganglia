{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase, basic_auth\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "neo4jUser = os.getenv(\"NEO4J_USER\")\n",
    "neo4jPwd = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\",auth=basic_auth(neo4jUser, neo4jPwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_of_type(label, session):\n",
    "    q = \"MATCH (n:%s) RETURN count(n)\" % label\n",
    "    res = session.run(q)\n",
    "    print(\"Added\", res.value()[0], \"nodes of type\", label)\n",
    "    \n",
    "def get_count_of_relationship(label, session):\n",
    "    q = \"MATCH ()-[r:%s]-() RETURN count(*)\" %label\n",
    "    res = session.run(q)\n",
    "    print(\"Added\", res.value()[0], \"relationships of type\", label)\n",
    "\n",
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/cells\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wipeddatabase cells\n"
     ]
    }
   ],
   "source": [
    "# Deleting all cell data in database\n",
    "with driver.session() as session:\n",
    "        session.run('''\n",
    "            MATCH (n)\n",
    "            WHERE  n:Cell\n",
    "                OR n:CellType \n",
    "                OR n:CellClass\n",
    "                OR n:CellGroup\n",
    "                OR n:CellPhenotype \n",
    "                OR n:CellPhenotypeCategory \n",
    "                OR n:CellularRegion\n",
    "                OR n:CellDescription\n",
    "                OR n:NeuralStructure\n",
    "            DETACH DELETE n\n",
    "        ''')\n",
    "        session.run('''\n",
    "            DROP CONSTRAINT ON (n:Cell) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:CellType) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:CellClass) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:CellGroup) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:CellPhenotype) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:CellPhenotypeCategory) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:CellDescription) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:NeuralStructure) ASSERT n.id IS UNIQUE\n",
    "            DROP INDEX ON :Cell(name)\n",
    "            DROP INDEX ON :CellType(name)\n",
    "            DROP INDEX ON :CellClass(name)\n",
    "            DROP INDEX ON :CellGroup(name)\n",
    "            DROP INDEX ON :CellPhenotype(name)\n",
    "            DROP INDEX ON :CellPhenotypeCategory(name)\n",
    "            DROP INDEX ON :NeuralStructure(name)\n",
    "        ''')\n",
    "        print(\"wipeddatabase cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 105 nodes of type CellType\n"
     ]
    }
   ],
   "source": [
    "# Adding CellType to graph from cell_types.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_types.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:CellType { id: row.ID, name: row.Cell_type_name, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(\"CREATE INDEX ON :CellType(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:CellType) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"CellType\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 8 nodes of type CellClass\n"
     ]
    }
   ],
   "source": [
    "# Adding CellClass to graph from cell_types.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_classes.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:CellClass { id: row.ID, name: row.Cell_class_name, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(\"CREATE INDEX ON :CellClass(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:CellClass) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"CellClass\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 3 nodes of type CellGroup\n"
     ]
    }
   ],
   "source": [
    "# Adding CellGroup to graph from cell_types.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_groups.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:CellGroup { id: row.ID, name: row.Cell_group_name, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(\"CREATE INDEX ON :CellGroup(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:CellGroup) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"CellGroup\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 107 nodes of type CellPhenotype\n"
     ]
    }
   ],
   "source": [
    "# Adding CellPhenotype from cell_phenotypes.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_phenotypes.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:CellPhenotype { id: row.ID, name: row.Phenotype, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:CellPhenotype) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE INDEX ON :CellPhenotype(name)\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"CellPhenotype\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 7 nodes of type CellPhenotypeCategory\n"
     ]
    }
   ],
   "source": [
    "# Adding CellPhenotypeCategory from cell_phenotype_categories.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_phenotype_categories.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:CellPhenotypeCategory { id:row.ID, name: row.Phenotype_category})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:CellPhenotypeCategory) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE INDEX ON :CellPhenotypeCategory(name)\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"CellPhenotypeCategory\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 nodes of type CellularRegion\n"
     ]
    }
   ],
   "source": [
    "# Adding CellularRegion from cellular_regions.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cellular_regions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:CellularRegion { id:row.ID, name: row.Cellular_region, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:CellularRegion) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE INDEX ON :CellularRegion(name)\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"CellularRegion\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 12 nodes of type CellDescription\n"
     ]
    }
   ],
   "source": [
    "# Adding CellDescription from cell_descriptions.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_description.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:CellDescription { id: row.id, description: row.description, iri: row.iri})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:CellDescription) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"CellDescription\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 14 nodes of type NeuralStructure\n"
     ]
    }
   ],
   "source": [
    "# Adding NeuralStructure from objects_of_intrest.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"objects_of_interest.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:NeuralStructure { id:row.ID, name: row.Object_of_interest, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:NeuralStructure) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE INDEX ON :NeuralStructure(name)\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"NeuralStructure\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/experiments\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wipeddatabase\n"
     ]
    }
   ],
   "source": [
    "# Deleting all cell data in database\n",
    "with driver.session() as session:\n",
    "        session.run('''\n",
    "            MATCH (n)\n",
    "            WHERE  n:Calculation\n",
    "                OR n:StereologyDetail\n",
    "                OR n:Distribution\n",
    "                OR n:CellMorphology \n",
    "                OR n:Quantitation\n",
    "                OR n:Analysis\n",
    "                OR n:Experiment\n",
    "                OR n:SectioningDetail\n",
    "                OR n:SectioningInstrument\n",
    "                OR n:ReporterIncubation\n",
    "                OR n:Reporter\n",
    "                OR n:ReporterLabel\n",
    "                OR n:ReporterTarget\n",
    "                OR n:ReporterType\n",
    "                OR n:VisualizationProtocol\n",
    "                OR n:Solution\n",
    "                OR n:Software\n",
    "                OR n:Microscope\n",
    "                OR n:ElectronMicroscopeDetail\n",
    "                OR n:LightFluorescenceMicroscopeDetail\n",
    "            DETACH DELETE n\n",
    "        ''')\n",
    "        session.run('''\n",
    "            DROP CONSTRAINT ON (n:Distribution) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:CellMorphology) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:Quantitation) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:Analysis) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:Experiment) ASSERT n.id IS UNIQUE\n",
    "            DROP INDEX ON :Cell(Distribution)\n",
    "            DROP INDEX ON :CellType(CellMorphology)\n",
    "            DROP INDEX ON :CellPhenotype(Quantitation)\n",
    "            DROP INDEX ON :CellPhenotypeCategory(Analysis)\n",
    "            DROP INDEX ON :NeuralStructure(Experiment)\n",
    "        ''')\n",
    "        print(\"wipeddatabase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 958 nodes of type Calculation\n"
     ]
    }
   ],
   "source": [
    "# Adding Calculation to graph from calculations.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"calculations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Calculation { id: row.ID, description: row.Calculation_performed})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Calculation\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 212 nodes of type StereologyDetail\n"
     ]
    }
   ],
   "source": [
    "# Adding StereologyDetail to graph from stereology_details.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"stereology_details.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:StereologyDetail { id: row.ID, name: row.Stereology_details_name, probe: row.Probe, identificationFeature: row.Identification_feature, disectorHeight: toInt(row.Disector_height), areaSubfraction: toFloat(row.Area_subfraction), heightSubfraction: toFloat(row.Height_subfraction), investigatedSections: toFloat(row.Investigated_sections), investigatedFields: toInt(row.Investigated_fields), countedObjects: toInt(row.Counted_objects), coefficientOfError: toFloat(row.Coefficient_of_error), estimatedVolume: toFloat(row.Estimated_volume), volumeUnit: row.Volume_unit, anyExceptProbe: toInt(row.any_except_probe)})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"StereologyDetail\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 18 nodes of type Distribution\n"
     ]
    }
   ],
   "source": [
    "# Adding Distribution to graph from distributions.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"distributions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Distribution { id: row.ID, name: row.Distribution_name, sectionSampling: row.Section_sampling, samplingFraction: row.Sampling_fraction, subsectionalSampling: row.Subsectional_sampling, finalEstimateBasis: row.Final_estimate_basis, distribution: row.Distribution, distributionDimensions: row.Distribution_dimensions, analysisTypePrimary: row.Analysis_type_primary, analysisTypeSecondary: row.Analysis_type_secondary})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE INDEX ON :Distribution(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Distribution) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Distribution\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 50 nodes of type CellMorphology\n"
     ]
    }
   ],
   "source": [
    "# Adding CellMorphology to graph from cell_morphologies.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_morphologies.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:CellMorphology { id: row.ID, name: row.Morphology_name, neuromorphoId: row.Neuromorpho_ID, somaSurface: toFloat(row.Soma_surface), numberOfStems: toInt(row.Number_stems), numberOfBifurcations: toInt(row.Number_bifurcations), numberOfBranches: toInt(row.Number_branches), overallWidth: toFloat(row.Overall_width), overallHeight: toFloat(row.Overall_height), overallDepth: toFloat(row.Overall_depth), averageBranchDiameter: toFloat(row.Average_branch_diameter), averageContraction: toFloat(row.Average_contraction), totalArborLength: toFloat(row.Total_arbor_length), totalArborSurface: toFloat(row.Total_arbor_surface), totalArborVolume: toFloat(row.Total_arbor_volume), maxEuclideanDistance: toFloat(row.Max_Euclidean_distance), maxPathDistance: toFloat(row.Max_path_distance), maxBranchOrder: toInt(row.Max_branch_order), totalFragmentation: toInt(row.Total_fragmentation), partitionAsymmetry: toFloat(row.Partition_asymmetry), averageRalls: toInt(row.Average_Ralls), averageBifurcationAngleLocal: toFloat(row.Average_bifurcation_angle_local), averageBifurcationAngleRemote: toFloat(row.Average_bifurcation_angle_remote), fractalDimension: toFloat(row.Fractal_dimension), physicalIntegrity: row.Physical_integrity, structuralDomains: row.Structural_domains, morphologicalAttributes: row.Morphological_attributes, originalFormat: row.Original_format})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE INDEX ON :CellMorphology(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:CellMorphology) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"CellMorphology\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1074 nodes of type Quantitation\n"
     ]
    }
   ],
   "source": [
    "# Adding Quantitation to graph from cell_morphologies.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"quantitations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Quantitation { id: row.ID, name: row.Quantitation_name, estimateRelevance: row.Estimate_relevance, sectionSampling: row.Section_sampling, samplingFraction: row.Sampling_fraction, subsectionalSampling: row.Subsectional_sampling, finalEstimateBasis: row.Final_estimate_basis, originalExtent: row.Original_extent, number: toInt(row.Number), numberSD: toInt(row.Number_SD), density: toFloat(row.Density), densityUnit: row.Density_unit, densitySD: toInt(row.Density_SD), volumetricDensity: toInt(row.Volumetric_density), estimateExtraction: row.Estimate_extraction})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session: \n",
    "    session.run(\"CREATE INDEX ON :Quantitation(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Quantitation) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Quantitation\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 668 nodes of type Analysis\n"
     ]
    }
   ],
   "source": [
    "# Adding Analysis to graph from derived_data_records.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_data_records.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Analysis { id: row.ID, name: row.Derived_data_record_name, numberOfAnimals: row.Number_of_animals, dataType: row.Derived_data_type, shrinkageCorrection: row.Shrinkage_correction })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(\"CREATE INDEX ON :Analysis(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Analysis) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Analysis\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 375 nodes of type Experiment\n"
     ]
    }
   ],
   "source": [
    "# Adding Experiment to graph from experiments.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"experiments.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Experiment { id: row.ID, name: row.Experiment_name, animalStatus: row.Animal_status, ageLowerLimit: toInt(row.Age_lower_limit), ageUpperLimit: toInt(row.Age_upper_limit), weightLowerLimit: toInt(row.Weight_lower_limit), weightUpperLimit: toInt(row.Weight_upper_limit) })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session: \n",
    "    session.run(\"CREATE INDEX ON :Experiment(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Experiment) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Experiment\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 510 nodes of type SectioningDetail\n"
     ]
    }
   ],
   "source": [
    "# Adding SectioningDetail to graph from sectioning_details.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"sectioning_details.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:SectioningDetail { id: row.ID, sectionThickness: toFloat(row.Section_thickness), sectionOrientation: row.Section_orientation })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"SectioningDetail\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 6 nodes of type SectioningInstrument\n"
     ]
    }
   ],
   "source": [
    "# Adding SectioningInstrument to graph from sectioning_instruments.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"sectioning_instruments.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:SectioningInstrument { id: row.ID, name: row.Sectioning_instrument_name })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"SectioningInstrument\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 713 nodes of type ReporterIncubation\n"
     ]
    }
   ],
   "source": [
    "# Adding ReporterIncubation to graph from reporter_incumations.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"reporter_incubations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:ReporterIncubation { id: row.ID, order: row.Order, concentration: row.Concentration, time: toFloat(row.Time), temperature: toInt(row.temperature) })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"ReporterIncubation\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 249 nodes of type Reporter\n"
     ]
    }
   ],
   "source": [
    "# Adding Reporter to graph from reporters.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"reporters.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Reporter { id: row.ID, name: row.Name, type: row.Reporter_type, uniqueId: row.Reporter_unique_ID, comment: row.Comment, originSpecie: row.Origin_species  })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Reporter\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 23 nodes of type ReporterLabel\n"
     ]
    }
   ],
   "source": [
    "# Adding ReporterLabel to graph from reporter_labels.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"reporter_labels.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:ReporterLabel { id: row.ID, name: row.Label})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"ReporterLabel\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 100 nodes of type ReporterTarget\n"
     ]
    }
   ],
   "source": [
    "# Adding ReporterTarget to graph from reporter_targets.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"reporter_targets.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:ReporterTarget { id: row.ID, phenotype: row.Phenotype})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"ReporterTarget\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 12 nodes of type VisualizationProtocol\n"
     ]
    }
   ],
   "source": [
    "# Adding VisualizationProtocol to graph from visualization_protocols.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"visualization_protocols.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:VisualizationProtocol { id: row.ID, name: row.Protocol_name, ontology: row.Ontological_identifier })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"VisualizationProtocol\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 266 nodes of type Solution\n"
     ]
    }
   ],
   "source": [
    "# Adding Solution to graph from solutions.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"solutions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Solution { id: row.ID, name: row.Solution_name })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Solution\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 9 nodes of type Microscope\n"
     ]
    }
   ],
   "source": [
    "# Adding Microscope to graph from microscopes.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"microscopes.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Microscope { id: row.ID, type: row.Microscope_type, ontology: row.Ontological_identifier })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Microscope\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 27 nodes of type ElectronMicroscopeDetail\n"
     ]
    }
   ],
   "source": [
    "# Adding ElectronMicroscopeDetail to graph from electron_microscopy_details.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"electron_microscopy_details.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:ElectronMicroscopeDetail { id: row.ID, name: row.EM_details_name, gridType: row.Grid_type, magnification: row.Magnification })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"ElectronMicroscopeDetail\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 238 nodes of type LightFluorescenceMicroscopeDetail\n"
     ]
    }
   ],
   "source": [
    "# Adding LightFluorescenceMicroscopeDetail to graph from light_fluorescence_microscopy_details.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"light_fluorescence_microscopy_details.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:LightFluorescenceMicroscopeDetail { id: row.ID, name: row.Microscopy_details_name, mountingMedium: toInt(row.Mounting_medium), refractionMedium: row.Refraction_medium, numericalAperature: toFloat(row.Numerical_aperture), objectiveLens: row.Objective_lens, totalMagnification: row.Total_magnification, pixelSize: toFloat(row.Pixel_size), z_stack: toBoolean(row.Z_stack), opticalSliceSize: row.Optical_slice_size })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"LightFluorescenceMicroscopeDetail\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 50 nodes of type Software\n"
     ]
    }
   ],
   "source": [
    "# Adding Software to graph from softwares.csv\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"softwares.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Software { id: row.ID, name: row.Software_name, rrid: row.Software_RRID })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Software\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REGIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/regions\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wipeddatabase\n"
     ]
    }
   ],
   "source": [
    "# Deleting all region data in database\n",
    "with driver.session() as session:\n",
    "        session.run('''\n",
    "            MATCH (n)\n",
    "            WHERE  n:BrainRegion \n",
    "                OR n:RegionZone \n",
    "                OR n:RegionRecord \n",
    "                OR n:Nomenclature\n",
    "                OR n:RegionOther\n",
    "                OR n:BamsRegion\n",
    "            DETACH DELETE n\n",
    "            \n",
    "        ''')\n",
    "        session.run('''\n",
    "            DROP CONSTRAINT ON (n:BrainRegion) ASSERT n.id IS UNIQUE\n",
    "            DROP INDEX ON :BrainRegion(name)\n",
    "            DROP CONSTRAINT ON (n:Nomenclature) ASSERT n.id IS UNIQUE\n",
    "            DROP INDEX ON :Nomenclature(name)\n",
    "            DROP CONSTRAINT ON (n:RegionOther) ASSERT n.id IS UNIQUE\n",
    "            DROP INDEX ON :RegionOther(name)\n",
    "            DROP CONSTRAINT ON (n:BamsRegion) ASSERT n.id IS UNIQUE\n",
    "            DROP INDEX ON :BamsRegion(name)\n",
    "        ''')\n",
    "        print(\"wipeddatabase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 88 nodes of type BrainRegion\n"
     ]
    }
   ],
   "source": [
    "# Adding regions to graph with BrainRegion label\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"regions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (d:BrainRegion {id: row.ID, name: row.Region_name, abbreviation: row.Abbreviation, comments: row.Comments})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(\"CREATE CONSTRAINT ON (n:BrainRegion) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE INDEX ON :BrainRegion(name)\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"BrainRegion\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 313 nodes of type RegionRecord\n"
     ]
    }
   ],
   "source": [
    "# Adding region_records to graph with RegionRecord label\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_records.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:RegionRecord { id: row.ID, name: row.Region_record_name, coverage: row.Coverage, specificity: row.Specificity, numberOfOriginalRegions: toInt(row.No_original_regions), originalRegionRetained: toInt(row.Original_region_retained), parcellationScheme: row.Parcellation_scheme, atlasCoordinates: row.Atlas_coordinates, illustration: row.Illustration, semanticDescription: row.Semantic_description, annotatedImages: row.Annotated_images, regionalCharacteristics: row.Regional_characteristics, isAtlasRegion: row.Atlas_reg, serialSections: row.Serial_sections, collectorsComment: row.Collectors_comment, documentationScore: toInt(row.Documentation_score)})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"RegionRecord\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 79 nodes of type RegionZone\n"
     ]
    }
   ],
   "source": [
    "# Adding region_zones to graph with RegionZone label\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_zones.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:RegionZone { id: row.ID, name: row.Region_zone, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"RegionZone\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 3 nodes of type Nomenclature\n"
     ]
    }
   ],
   "source": [
    "# Adding nomenclatures to graph with Nomenclature label\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"nomenclatures.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Nomenclature { id: row.ID, name: row.Nomenclature_name, version: row.Version, authors: row.Authors, published: toInt(row.Published), publication_type: row.Publication_type, doi: row.DOI, preferred: 1})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Nomenclature) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE INDEX ON :Nomenclature(name)\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Nomenclature\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 19 nodes of type Nomenclature\n"
     ]
    }
   ],
   "source": [
    "# Adding nomebclatures_other to graph with Nomenclature label\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"nomenclatures_other.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Nomenclature { id: row.ID, name: row.Nomenclature_name, version: row.Version, authors: row.Authors, published: toInt(row.Published), publicationType: row.Publication_type, preferred: 0 })\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Nomenclature\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 272 nodes of type RegionOther\n"
     ]
    }
   ],
   "source": [
    "# Adding regions_other to graph with RegionOther label\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"regions_other.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (d:RegionOther {id: row.ID, name: row.Region_name, abbreviation: row.Abbreviation, comments: row.Comments})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(\"CREATE CONSTRAINT ON (n:RegionOther) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE INDEX ON :RegionOther(name)\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"RegionOther\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 80 nodes of type BamsRegion\n"
     ]
    }
   ],
   "source": [
    "# Adding bams2_regions to graph with BamsRegion label\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"bams2_regions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (d:BamsRegion {id: row.id, name: row.name, description: row.description})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(\"CREATE CONSTRAINT ON (n:BamsRegion) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE INDEX ON :BamsRegion(name)\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"BamsRegion\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOURCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/sources\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wipeddatabase\n"
     ]
    }
   ],
   "source": [
    "# Deleting all source data in database\n",
    "with driver.session() as session:\n",
    "        session.run('''\n",
    "            MATCH (n)\n",
    "            WHERE  n:Source\n",
    "                OR n:SourceOrigin\n",
    "                OR n:ConsideredPaper\n",
    "                OR n:ExclusionReason\n",
    "            DETACH DELETE n\n",
    "        ''')\n",
    "        session.run('''\n",
    "            DROP CONSTRAINT ON (n:Source) ASSERT n.id IS UNIQUE\n",
    "            DROP INDEX ON :Source(Source)\n",
    "        ''')\n",
    "        print(\"wipeddatabase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 246 nodes of type Source\n"
     ]
    }
   ],
   "source": [
    "# Adding Source to graph from sources.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"sources.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Source {id: row.ID, title: row.Source_title, type: row.Source_type, insertedData: row.Inserted_date, publicationYear: toInt(row.Source_publication_year), sourceName: row.Source_name})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE INDEX ON :Source(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Source) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Source\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 363 nodes of type SourceOrigin\n"
     ]
    }
   ],
   "source": [
    "# Adding SourceOrigin to graph from sources.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"source_origins_lookup.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:SourceOrigin {id: row.ID, name: row.Source_name, identifier: row.Identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"SourceOrigin\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2204 nodes of type ConsideredPaper\n",
      "Number of considered papers that are included: 244\n"
     ]
    }
   ],
   "source": [
    "# Adding ConsideredPaper to graph from sources.csv\n",
    "## TODO try to connect considered_paper and publication \n",
    "## based on first auth + year (published) with Source_name\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"considered_papers.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:ConsideredPaper {id: row.ID, title: row.Title, publishedYear: toInt(row.Published), firstAuthor: row.First_author, isIncluded: false})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    session.run(\"create index on :ConsideredPaper(id)\")\n",
    "    get_count_of_type(\"ConsideredPaper\", session)\n",
    "    \n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"considered_papers_desicions.csv\")\n",
    "\n",
    "included_query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        WITH row WHERE row.Decision =~ \".*(?i)Included.*\"\n",
    "        MATCH (n:ConsideredPaper {id: row.Paper})\n",
    "        SET n.isIncluded = true\n",
    "        RETURN COUNT(n)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    res = session.run(included_query)\n",
    "    print(\"Number of considered papers that are included:\",  res.value()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 13 nodes of type ExclusionReason\n",
      "Added 4226 relationships of type EXCLUSION_REASON\n"
     ]
    }
   ],
   "source": [
    "### Process considered paper decisions to find reasons where considered paper can get a relation to the reaseon.\n",
    "## IF it doesnt have relation to excluded it  is included \n",
    "\n",
    "import pandas as pd\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"considered_papers_desicions.csv\")\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "exclusion_reasons = df[\"Decision\"].unique()\n",
    "\n",
    "with driver.session() as session: \n",
    "    for reason in exclusion_reasons:\n",
    "        if type(reason) == str and \"included\" not in reason.lower():\n",
    "\n",
    "            q = \"CREATE (:ExclusionReason {reason: '%s'})\" % reason.replace(\"Excluded: \", \"\")\n",
    "            session.run(q)\n",
    "            \n",
    "            # Relationship EXCLUSION_REASON between ConsideredPaper and ExclusionReason\n",
    "            query=\"\"\"\n",
    "                    LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "                    WITH row where row.Decision = '%s'\n",
    "                    MATCH (a:ConsideredPaper { id: row.Paper})\n",
    "                    MATCH (c:ExclusionReason { reason: '%s' })\n",
    "                    MERGE (a)-[:EXCLUSION_REASON]->(c)\n",
    "                \"\"\" % (csv_file_path, reason,  reason.replace(\"Excluded: \", \"\"))\n",
    "\n",
    "            session.run(query)\n",
    "    get_count_of_type(\"ExclusionReason\", session)\n",
    "    get_count_of_relationship(\"EXCLUSION_REASON\", session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/subjects\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wipeddatabase\n"
     ]
    }
   ],
   "source": [
    "# Deleting all subject data in database\n",
    "with driver.session() as session:\n",
    "        session.run('''\n",
    "            MATCH (n)\n",
    "            WHERE  n:Specimen\n",
    "                OR n:Specie \n",
    "                OR n:Strain \n",
    "                OR n:Substrain \n",
    "                OR n:Sex\n",
    "                OR n:AgeCategory\n",
    "                OR n:TransgenicLine\n",
    "            DETACH DELETE n\n",
    "        ''')\n",
    "        session.run('''\n",
    "            DROP CONSTRAINT ON (n:Specimen) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:Specie) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:Strain) ASSERT n.id IS UNIQUE\n",
    "            DROP CONSTRAINT ON (n:Substrains) ASSERT n.id IS UNIQUE\n",
    "            DROP INDEX ON :Specimen(name)\n",
    "            DROP INDEX ON :Specie(name)\n",
    "            DROP INDEX ON :Strain(name)\n",
    "            DROP INDEX ON :Substrains(name)\n",
    "        ''')\n",
    "        print(\"wipeddatabase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1065 nodes of type Specimen\n"
     ]
    }
   ],
   "source": [
    "# Adding Specimen to graph from specimens.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"specimens.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Specimen {id: row.ID, name: row.Specimen_name, form: row.Specimen_form, order: row.Specimen_order})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE INDEX ON :Specimen(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Specimen) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Specimen\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 24 nodes of type Strain\n"
     ]
    }
   ],
   "source": [
    "# Adding Strain to graph from strains.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"strains.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Strain {id: row.ID, name: row.Strain_name, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE INDEX ON :Strain(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Strain) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Strain\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 44 nodes of type Substrain\n"
     ]
    }
   ],
   "source": [
    "# Adding Substrain to graph from substrains.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"substrains.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Substrain {id: row.ID, name: row.Substrain_name, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE INDEX ON :Substrain(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Substrain) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Substrain\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 nodes of type Specie\n"
     ]
    }
   ],
   "source": [
    "# Adding Specie to graph from species.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"species.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Specie {id: row.ID, name: row.Species, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE INDEX ON :Specie(name)\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:Specie) ASSERT n.id IS UNIQUE\")\n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Specie\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 nodes of type AgeCategory\n"
     ]
    }
   ],
   "source": [
    "# Adding AgeCategory to graph from age_categories.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"age_categories.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:AgeCategory {id: row.ID, name: row.Age_category, ontology: row.Ontological_identifier, description: row.Description})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"AgeCategory\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 3 nodes of type Sex\n"
     ]
    }
   ],
   "source": [
    "# Adding Sex to graph from sex.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"sex.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:Sex {id: row.ID, name: row.Sex, ontology: row.Ontological_identifier})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"Sex\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 20 nodes of type TransgenicLine\n"
     ]
    }
   ],
   "source": [
    "# Adding TransgenicLine to graph from transgenic_lines.csv\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"transgenic_lines.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        CREATE (:TransgenicLine {id: row.ID, name: row.Transgenic_line_name, RRID: row.Transgenic_line_RRID})\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:    \n",
    "    session.run(query)\n",
    "    get_count_of_type(\"TransgenicLine\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CELL RELATIONSHIPS\n",
    "\n",
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/cells\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 16 relationships of type CELL_GROUP_MEMBERSHIP\n"
     ]
    }
   ],
   "source": [
    "# Relationship CELL_GROUP_MEMBERSHIP between CellClass and CellGroup\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_classes.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellClass { id: row.ID})\n",
    "        MATCH (c:CellGroup { id: row.Cell_group_membership })\n",
    "        MERGE (a)-[:CELL_GROUP_MEMBERSHIP]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"CELL_GROUP_MEMBERSHIP\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 210 relationships of type CELL_CLASS_MEMBERSHIP\n"
     ]
    }
   ],
   "source": [
    "# Relationship CELL_CLASS_MEMBERSHIP between CellType and CellClass\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_types.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellType { id: row.ID})\n",
    "        MATCH (c:CellClass { id: row.Cell_class_membership })\n",
    "        MERGE (a)-[:CELL_CLASS_MEMBERSHIP]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"CELL_CLASS_MEMBERSHIP\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 210 relationships of type PHENOTYPE_CATEGORY\n"
     ]
    }
   ],
   "source": [
    "# Relationship PHENOTYPE_CATEGORY between CellPhenotype and CellPhenotypeCategory\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_phenotypes.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellPhenotype { id: row.ID})\n",
    "        MATCH (c:CellPhenotypeCategory { id: row.Phenotype_category })\n",
    "        MERGE (a)-[:PHENOTYPE_CATEGORY]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"PHENOTYPE_CATEGORY\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 322 relationships of type PHENOTYPE\n"
     ]
    }
   ],
   "source": [
    "# Relationship PHENOTYPE between Cell and CellPhenotype\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"celltype_phenotype.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellType { id: row.CellID})\n",
    "        MATCH (c:CellPhenotype { id: row.PhenotypeID })\n",
    "        MERGE (a)-[:PHENOTYPE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"PHENOTYPE\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 32 relationships of type CELL_DESCRIPTION\n"
     ]
    }
   ],
   "source": [
    "# Relationship CELL_DESCRIPTION between CellType, CellClass, CellGroup and CellDescription\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_description.csv\")\n",
    "type_query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellType { id: row.cell_type_id})\n",
    "        MATCH (c:CellDescription { id: row.id })\n",
    "        MERGE (a)-[:CELL_DESCRIPTION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "class_query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellClass { id: row.cell_class_id})\n",
    "        MATCH (c:CellDescription { id: row.id })\n",
    "        MERGE (a)-[:CELL_DESCRIPTION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "group_query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellGroup { id: row.cell_group_id})\n",
    "        MATCH (c:CellDescription { id: row.id })\n",
    "        MERGE (a)-[:CELL_DESCRIPTION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(type_query)\n",
    "    session.run(class_query)\n",
    "    session.run(group_query)\n",
    "    get_count_of_relationship(\"CELL_DESCRIPTION\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPERIMENT RELATIONSHIPS\n",
    "\n",
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/experiments\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")\n",
    "\n",
    "def get_count_of_relationship(rel_label, fromLabel, toLabel, session):\n",
    "    q = \"MATCH (:%s)-[r:%s]-(:%s) RETURN count(*)\" % (fromLabel, rel_label, toLabel)\n",
    "    res = session.run(q)\n",
    "    print(\"Added\", res.value()[0], \"relationships of type\", fromLabel, rel_label, toLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 134 relationships of type NeuralStructure BELONGS_TO CellType\n"
     ]
    }
   ],
   "source": [
    "# Relationship BELONGS_TO between NeuralStructure and Cell\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_data_records.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:NeuralStructure { id: row.Object_of_interest})\n",
    "        MATCH (c:CellType { id: row.Cell_type_putative })\n",
    "        MERGE (a)-[:BELONGS_TO]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"BELONGS_TO\",\"NeuralStructure\",\"CellType\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 27 relationships of type ElectronMicroscopeDetail MICROSCOPE_TYPE Microscope\n",
      "Added 238 relationships of type LightFluorescenceMicroscopeDetail MICROSCOPE_TYPE Microscope\n",
      "Added 59 relationships of type Analysis MICROSCOPE ElectronMicroscopeDetail\n",
      "Added 538 relationships of type Analysis MICROSCOPE LightFluorescenceMicroscopeDetail\n"
     ]
    }
   ],
   "source": [
    "## Microscope RELATIONS\n",
    "\n",
    "# :ElectronMicroscopeDetail - :MICROSCOPE_TYPE - :Microscope\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"electron_microscopy_details.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:ElectronMicroscopeDetail { id: row.ID})\n",
    "        MATCH (c:Microscope { id: row.Microscope })\n",
    "        MERGE (a)-[:MICROSCOPE_TYPE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"MICROSCOPE_TYPE\", \"ElectronMicroscopeDetail\", \"Microscope\", session)\n",
    "    \n",
    "# :LightFluorescenceMicroscopeDetail - :MICROSCOPE_TYPE - :Microscope\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"light_fluorescence_microscopy_details.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:LightFluorescenceMicroscopeDetail { id: row.ID})\n",
    "        MATCH (c:Microscope { id: row.Microscope })\n",
    "        MERGE (a)-[:MICROSCOPE_TYPE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"MICROSCOPE_TYPE\", \"LightFluorescenceMicroscopeDetail\", \"Microscope\", session)\n",
    "\n",
    "# :Analysis - :MICROSCOPE - :ElectronMicroscopeDetail\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_data_EMdetails.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.Derived_data_record})\n",
    "        MATCH (c:ElectronMicroscopeDetail { id: row.EMdetails })\n",
    "        MERGE (a)-[:MICROSCOPE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"MICROSCOPE\", \"Analysis\", \"ElectronMicroscopeDetail\", session)\n",
    "\n",
    "# :Analysis - :MICROSCOPE - :LightFluorescenceMicroscopeDetail\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_data_LFMdetails.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.Derived_data_record_ID})\n",
    "        MATCH (c:LightFluorescenceMicroscopeDetail { id: row.LFMdetails_ID })\n",
    "        MERGE (a)-[:MICROSCOPE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"MICROSCOPE\", \"Analysis\", \"LightFluorescenceMicroscopeDetail\", session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 246 relationships of type Reporter LABEL ReporterLabel\n",
      "Added 241 relationships of type Reporter TARGET ReporterTarget\n"
     ]
    }
   ],
   "source": [
    "## Reporter RELATIONS\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"reporters.csv\")\n",
    "\n",
    "## :Reporter - :LABEL - :ReporterLabel\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Reporter { id: row.ID})\n",
    "        MATCH (c:ReporterLabel { id: row.Label })\n",
    "        MERGE (a)-[:LABEL]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"LABEL\", \"Reporter\", \"ReporterLabel\", session)\n",
    "    \n",
    "## :Reporter - :TARGET - :ReporterTarget\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Reporter { id: row.ID})\n",
    "        MATCH (c:ReporterTarget { id: row.Target })\n",
    "        MERGE (a)-[:TARGET]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"TARGET\", \"Reporter\", \"ReporterTarget\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 382 relationships of type SectioningDetail SECTIONED_BY SectioningInstrument\n"
     ]
    }
   ],
   "source": [
    "## SectioningDetail RELATIONS\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"sectioning_details.csv\")\n",
    "\n",
    "## :SectioningDetail - :SECTIONED_BY - :SectioningInstrument\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:SectioningDetail { id: row.ID})\n",
    "        MATCH (c:SectioningInstrument { id: row.Sectioning_instrument })\n",
    "        MERGE (a)-[:SECTIONED_BY]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"SECTIONED_BY\", \"SectioningDetail\", \"SectioningInstrument\", session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 713 relationships of type ReporterIncubation REPORTER Reporter\n"
     ]
    }
   ],
   "source": [
    "## ReporterIncubation RELATIONS\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"reporter_incubations.csv\")\n",
    "\n",
    "## :ReporterIncubation - :REPORTER - :Reporter\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:ReporterIncubation { id: row.ID})\n",
    "        MATCH (c:Reporter { id: row.Reporter })\n",
    "        MERGE (a)-[:REPORTER]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REPORTER\", \"ReporterIncubation\", \"Reporter\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 313 relationships of type Experiment ANAESTHETIC Solution\n",
      "Added 312 relationships of type Experiment PERFUSION_FIX_MEDIUM Solution\n",
      "Added 375 relationships of type Experiment DATA_ORIGIN Source\n"
     ]
    }
   ],
   "source": [
    "### Experiment RELATIONS\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"experiments.csv\")\n",
    "\n",
    "## :Experiment - :ANAESTHETIC - :Solution\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Experiment { id: row.ID})\n",
    "        MATCH (c:Solution { id: row.Anaesthetic })\n",
    "        MERGE (a)-[:ANAESTHETIC]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"ANAESTHETIC\", \"Experiment\", \"Solution\", session)\n",
    "    \n",
    "## :Experiment - :PERFUSION_FIX_MEDIUM - :Solution\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Experiment { id: row.ID})\n",
    "        MATCH (c:Solution { id: row.Perfusion_fix_medium })\n",
    "        MERGE (a)-[:PERFUSION_FIX_MEDIUM]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"PERFUSION_FIX_MEDIUM\", \"Experiment\", \"Solution\", session)\n",
    "\n",
    "## :Experiment - :DATA_ORIGIN - :Source\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Experiment { id: row.ID})\n",
    "        MATCH (c:Source { id: row.Source })\n",
    "        MERGE (a)-[:DATA_ORIGIN]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"DATA_ORIGIN\", \"Experiment\", \"Source\", session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 668 relationships of type Analysis SPECIMEN Specimen\n",
      "Added 668 relationships of type Analysis OBJECT_OF_INTEREST NeuralStructure\n",
      "Added 668 relationships of type Analysis CELL_TYPE_PUTATIVE CellType\n",
      "Added 666 relationships of type Analysis VISUALIZATION_METHOD VisualizationProtocol\n"
     ]
    }
   ],
   "source": [
    "### Analysis RELATIONS \n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_data_records.csv\")\n",
    "\n",
    "## :Analysis - :SPECIMEN - :Specimen \n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.ID})\n",
    "        MATCH (c:Specimen { id: row.Specimen })\n",
    "        MERGE (a)-[:SPECIMEN]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"SPECIMEN\", \"Analysis\", \"Specimen\", session)\n",
    "    \n",
    "## :Analysis - :OBJECT_OF_INTEREST - :NeuralStructure\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.ID})\n",
    "        MATCH (c:NeuralStructure { id: row.Object_of_interest })\n",
    "        MERGE (a)-[:OBJECT_OF_INTEREST]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"OBJECT_OF_INTEREST\", \"Analysis\", \"NeuralStructure\", session)\n",
    "    \n",
    "## Add property to :Analysis - :OBJECT_OF_INTEREST - :NeuralStructure\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis)-[r:OBJECT_OF_INTEREST]-(b:NeuralStructure)\n",
    "        WHERE row.OOI_recognition_criteria IS NOT NULL\n",
    "        SET r.recognitionCriteria = row.OOI_recognition_criteria\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    \n",
    "## :Analysis - :CELL_TYPE_PUTATIVE - :Cell\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.ID})\n",
    "        MATCH (c:CellType { id: row.Cell_type_putative })\n",
    "        MERGE (a)-[:CELL_TYPE_PUTATIVE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"CELL_TYPE_PUTATIVE\", \"Analysis\", \"CellType\", session)\n",
    "    \n",
    "## :Analysis - :VISUALIZATION_METHOD - :VisualizationProtocol\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.ID})\n",
    "        MATCH (c:VisualizationProtocol { id: row.Visualization_method })\n",
    "        MERGE (a)-[:VISUALIZATION_METHOD]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"VISUALIZATION_METHOD\", \"Analysis\", \"VisualizationProtocol\", session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1074 relationships of type Analysis DATA_TYPE Quantitation\n",
      "Added 1074 relationships of type Quantitation REGION_RECORD RegionRecord\n",
      "Added 453 relationships of type Quantitation REGION_ZONE RegionZone\n",
      "Added 102 relationships of type Quantitation CELLULAR_TARGET_REGION CellularRegion\n",
      "Added 15 relationships of type Quantitation TARGET_CELL CellType\n",
      "Added 418 relationships of type Quantitation STEREOLOGY StereologyDetail\n",
      "Added 658 relationships of type Quantitation SOFTWARE Software\n",
      "Added 958 relationships of type Quantitation CALCULATION Calculation\n"
     ]
    }
   ],
   "source": [
    "### Quantitation RELATIONS\n",
    "\n",
    "## :Analysis - :DATA_TYPE - :Quantitation\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"quantitations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.Derived_data_record})\n",
    "        MATCH (c:Quantitation { id: row.ID })\n",
    "        MERGE (a)-[:DATA_TYPE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"DATA_TYPE\", \"Analysis\", \"Quantitation\", session)\n",
    "    \n",
    "## :Quantitation - :REGION_RECORD - :RegionRecord\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"quantitations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Quantitation { id: row.ID})\n",
    "        MATCH (c:RegionRecord { id: row.Region_record })\n",
    "        MERGE (a)-[:REGION_RECORD]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REGION_RECORD\", \"Quantitation\", \"RegionRecord\", session)\n",
    "    \n",
    "## :Quantitation - :REGION_ZONE - :RegionZone\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"quantitations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Quantitation { id: row.ID})\n",
    "        MATCH (c:RegionZone { id: row.Region_zone })\n",
    "        MERGE (a)-[:REGION_ZONE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REGION_ZONE\", \"Quantitation\", \"RegionZone\", session)\n",
    "    \n",
    "## :Quantitation - :CELLULAR_TARGET_REGION - :CellularRegion\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"quantitations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Quantitation { id: row.ID})\n",
    "        MATCH (c:CellularRegion { id: row.Cellular_target_region })\n",
    "        MERGE (a)-[:CELLULAR_TARGET_REGION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"CELLULAR_TARGET_REGION\", \"Quantitation\", \"CellularRegion\", session)\n",
    "    \n",
    "## :Quantitation - :TARGET_CELL - :Cell\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"quantitations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Quantitation { id: row.ID})\n",
    "        MATCH (c:CellType { id: row.Cellular_target_ID })\n",
    "        MERGE (a)-[:TARGET_CELL]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"TARGET_CELL\", \"Quantitation\", \"CellType\", session)\n",
    "\n",
    "## :Quantitation - :STEREOLOGY - :StereologyDetail\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"quantitations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Quantitation { id: row.ID})\n",
    "        MATCH (c:StereologyDetail { id: row.Stereology_details_record })\n",
    "        MERGE (a)-[:STEREOLOGY]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"STEREOLOGY\", \"Quantitation\", \"StereologyDetail\", session)\n",
    "    \n",
    "## :Quantitation - :SOFTWARE - :Software\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"quantitations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Quantitation { id: row.ID})\n",
    "        MATCH (c:Software { id: row.Software })\n",
    "        MERGE (a)-[:SOFTWARE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"SOFTWARE\", \"Quantitation\", \"Software\", session)\n",
    "    \n",
    "## :Quantitation - :CALCULATION - :Calculation\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"calculations.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Quantitation { id: row.Quantitation_ID})\n",
    "        MATCH (c:Calculation { id: row.ID })\n",
    "        MERGE (a)-[:CALCULATION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"CALCULATION\", \"Quantitation\", \"Calculation\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 50 relationships of type Analysis DATA_TYPE CellMorphology\n",
      "Added 50 relationships of type CellMorphology REGION_RECORD RegionRecord\n",
      "Added 37 relationships of type CellMorphology REGION_ZONE RegionZone\n",
      "Added 50 relationships of type CellMorphology RECONSTRUCTED_WITH Software\n"
     ]
    }
   ],
   "source": [
    "### CellMorphology RELATIONS\n",
    "\n",
    "## :Analysis - :DATA_TYPE - :CellMorphology\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_morphologies.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.Derived_data_record})\n",
    "        MATCH (c:CellMorphology { id: row.ID })\n",
    "        MERGE (a)-[:DATA_TYPE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"DATA_TYPE\", \"Analysis\", \"CellMorphology\", session)\n",
    "\n",
    "## :CellMorphology - :REGION_RECORD - :RegionRecord\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_morphologies.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellMorphology { id: row.ID})\n",
    "        MATCH (c:RegionRecord { id: row.Region_record })\n",
    "        MERGE (a)-[:REGION_RECORD]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REGION_RECORD\", \"CellMorphology\", \"RegionRecord\", session)\n",
    "    \n",
    "## :CellMorphology - :REGION_ZONE - :RegionZone\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_morphologies.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellMorphology { id: row.ID})\n",
    "        MATCH (c:RegionZone { id: row.Region_zone })\n",
    "        MERGE (a)-[:REGION_ZONE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REGION_ZONE\", \"CellMorphology\", \"RegionZone\", session)\n",
    "    \n",
    "## :CellMorphology - :RECONSTRUCTED_WITH - :Software\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"cell_morphologies.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:CellMorphology { id: row.ID})\n",
    "        MATCH (c:Software { id: row.Reconstruction_method })\n",
    "        MERGE (a)-[:RECONSTRUCTED_WITH]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"RECONSTRUCTED_WITH\", \"CellMorphology\", \"Software\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 18 relationships of type Analysis DATA_TYPE Distribution\n",
      "Added 10 relationships of type Distribution PERFORMED_ON Software\n",
      "Added 4 relationships of type Distribution CELLULAR_REGION CellularRegion\n",
      "Added 18 relationships of type Distribution REGION_RECORD RegionRecord\n",
      "Added 4 relationships of type Distribution STEREOLOGY StereologyDetail\n",
      "Added 16 relationships of type Distribution RELATED_TO Quantitation\n"
     ]
    }
   ],
   "source": [
    "### DISTRIBUTION RELATIONS\n",
    "\n",
    "## :Analysis - :DATA_TYPE - :Distribution\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"distributions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.Derived_data_record})\n",
    "        MATCH (c:Distribution { id: row.ID })\n",
    "        MERGE (a)-[:DATA_TYPE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"DATA_TYPE\", \"Analysis\", \"Distribution\", session)\n",
    "\n",
    "## :Distribution - :PERFORMED_ON - :Software \n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"distributions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Distribution { id: row.ID})\n",
    "        MATCH (c:Software { id: row.Software })\n",
    "        MERGE (a)-[:PERFORMED_ON]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"PERFORMED_ON\", \"Distribution\", \"Software\", session)\n",
    "    \n",
    "## :Distribution - :CELLULAR_REGION - :CellularRegion\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"distributions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Distribution { id: row.ID})\n",
    "        MATCH (c:CellularRegion { id: row.Cellular_region })\n",
    "        MERGE (a)-[:CELLULAR_REGION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    \n",
    "# Add property to :relation\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        WITH row WHERE row.Cellular_region_cytochemical_ID is not null\n",
    "        MATCH (a:Distribution {id: row.ID})-[r:CELLULAR_REGION]-(b:CellularRegion)\n",
    "        SET r.cytochemicalId = row.Cellular_region_cytochemical_ID\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"CELLULAR_REGION\", \"Distribution\", \"CellularRegion\", session)\n",
    "\n",
    "## :Distribution - :REGION_RECORD - :RegionRecord\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"distributions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Distribution { id: row.ID})\n",
    "        MATCH (c:RegionRecord { id: row.Region_record })\n",
    "        MERGE (a)-[:REGION_RECORD]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REGION_RECORD\", \"Distribution\", \"RegionRecord\", session)\n",
    "\n",
    "## :Distribution - :STEREOLOGY - :StereologyDetail\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"distributions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Distribution { id: row.ID})\n",
    "        MATCH (c:StereologyDetail { id: row.Stereology_details_record })\n",
    "        MERGE (a)-[:STEREOLOGY]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"STEREOLOGY\", \"Distribution\", \"StereologyDetail\", session)\n",
    "    \n",
    "## :Distribution - :RELATED_TO - :Quantitation\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"distributions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Distribution { id: row.ID})\n",
    "        MATCH (c:Quantitation { id: row.Related_quantitation })\n",
    "        MERGE (a)-[:RELATED_TO]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"RELATED_TO\", \"Distribution\", \"Quantitation\", session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 610 relationships of type Analysis SECTIONING_DETAIL SectioningDetail\n",
      "Added 906 relationships of type Analysis REPORTER_INCUBATION ReporterIncubation\n",
      "Added 668 relationships of type Analysis PART_OF_EXPERIMENT Experiment\n"
     ]
    }
   ],
   "source": [
    "### Derived relations from Experiments and Analysis (DDR) and Specimen\n",
    "\n",
    "## :Analysis - :SECTIONING_DETAIL - :SectioningDetail\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_sectioning_details.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.analysisId})\n",
    "        MATCH (c:SectioningDetail { id: row.sectioningDetailsId })\n",
    "        MERGE (a)-[:SECTIONING_DETAIL]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"SECTIONING_DETAIL\", \"Analysis\", \"SectioningDetail\", session)\n",
    "\n",
    "    \n",
    "## :Analysis - :REPORTER_INCUBATION - :ReporterIncubation\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_reporters.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.analysisId})\n",
    "        MATCH (c:ReporterIncubation { id: row.reporterId })\n",
    "        MERGE (a)-[:REPORTER_INCUBATION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REPORTER_INCUBATION\", \"Analysis\", \"ReporterIncubation\", session)\n",
    "    \n",
    "## :Analysis - :PART_OF_EXPERIMENT - :Experiment\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_experiments.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Analysis { id: row.analysisId})\n",
    "        MATCH (c:Experiment { id: row.experimentId })\n",
    "        MERGE (a)-[:PART_OF_EXPERIMENT]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"PART_OF_EXPERIMENT\", \"Analysis\", \"Experiment\", session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REGION RELATIONSHIPS\n",
    "\n",
    "def get_count_of_relationship(label, session):\n",
    "    q = \"MATCH ()-[r:%s]-() RETURN count(*)\" %label\n",
    "    res = session.run(q)\n",
    "    print(\"Added\", res.value()[0], \"relationships of type\", label)\n",
    "\n",
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/regions\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 624 relationships of type PRIMARY_REGION\n"
     ]
    }
   ],
   "source": [
    "# Relationship PRIMARY_REGION between BrainRegion and RegionRecord\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_records.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:RegionRecord { id: row.ID})\n",
    "        MATCH (c:BrainRegion { id: row.Region})\n",
    "        MERGE (a)-[:PRIMARY_REGION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"PRIMARY_REGION\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 58 relationships of type SECONDARY_REGION\n"
     ]
    }
   ],
   "source": [
    "# Relationship SECONDARY_REGION between BrainRegion and RegionRecord\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_records.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:RegionRecord { id: row.ID})\n",
    "        MATCH (c:BrainRegion { id: row.Secondary_region })\n",
    "        MERGE (a)-[:SECONDARY_REGION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"SECONDARY_REGION\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 620 relationships of type ORIGINAL_REGION\n"
     ]
    }
   ],
   "source": [
    "#Relationship ORIGINAL_REGION from RegionRecord to RegionOther\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"original_region_records.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:RegionRecord { id: row.Region_record})\n",
    "        MATCH (c:RegionOther { id: row.Original_region })\n",
    "        MERGE (a)-[:ORIGINAL_REGION]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "rel_query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:RegionRecord {id: row.Region_record})-[r:ORIGINAL_REGION]->(b:RegionOther)\n",
    "        SET r.originalCoordinateMinAP = row.Original_coord_AP_min\n",
    "        SET r.originalCoordinateMaxAP = row.Original_coord_AP_max\n",
    "        SET r.originalCoordinateMinDV = row.Original_coord_DV_min\n",
    "        SET r.originalCoordinateMaxDV = row.Original_coord_DV_max\n",
    "        SET r.originalCoordinateMinML = row.Original_coord_ML_min\n",
    "        SET r.originalCoordinateMaxML = row.Original_coord_ML_max\n",
    "\"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"ORIGINAL_REGION\", session)\n",
    "    session.run(rel_query)\n",
    "    \n",
    "# TODO CHECKK HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 38 relationships of type NOMENCLATURE_SPECIE\n"
     ]
    }
   ],
   "source": [
    "# Relationship NOMENCLATURE_SPECIE between Nomenclature and Specie\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"nomenclatures.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Nomenclature { id: row.ID})\n",
    "        MATCH (c:Specie { id: row.Species })\n",
    "        MERGE (a)-[:NOMENCLATURE_SPECIE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    \n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"nomenclatures_other.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Nomenclature { id: row.ID})\n",
    "        MATCH (c:Specie { id: row.Species })\n",
    "        MERGE (a)-[:NOMENCLATURE_SPECIE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"NOMENCLATURE_SPECIE\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 34 relationships of type NOMENCLATURE_STRAIN\n"
     ]
    }
   ],
   "source": [
    "# Relationship NOMENCLATURE_STRAIN between Nomenclature and Strain\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"nomenclatures.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Nomenclature { id: row.ID})\n",
    "        MATCH (c:Strain { id: row.Strain })\n",
    "        MERGE (a)-[:NOMENCLATURE_STRAIN]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    \n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"nomenclatures_other.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Nomenclature { id: row.ID})\n",
    "        MATCH (c:Strain { id: row.Strain })\n",
    "        MERGE (a)-[:NOMENCLATURE_STRAIN]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"NOMENCLATURE_STRAIN\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 544 relationships of type NAMING\n"
     ]
    }
   ],
   "source": [
    "# Relationship NAMING between RegionOther and Nomenclature\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"regions_other.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:RegionOther { id: row.ID})\n",
    "        MATCH (c:Nomenclature { id: row.Nomenclature })\n",
    "        MERGE (a)-[:NAMING]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"NAMING\", session)\n",
    "    \n",
    "# TODO CHECKK HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 720 relationships of type NAMING\n",
      "Added 544 relationships of type REGION_OTHER_NAMING\n"
     ]
    }
   ],
   "source": [
    "# Relationship NAMING between BrainRegion and Nomenclature\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"regions.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BrainRegion { id: row.ID})\n",
    "        MATCH (c:Nomenclature { id: row.Nomenclature })\n",
    "        MERGE (a)-[:NAMING]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"NAMING\", session)\n",
    "    \n",
    "# Relationship REGION_OTHER_NAMING between All RegionOther and Nomenclature\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"regions_other.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:RegionOther { id: row.ID})\n",
    "        MATCH (c:Nomenclature { id: row.Nomenclature })\n",
    "        MERGE (a)-[:REGION_OTHER_NAMING]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REGION_OTHER_NAMING\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 574 relationships of type ORIGINAL_FRAMEWORK\n"
     ]
    }
   ],
   "source": [
    "# Relationship ORIGINAL_FRAMEWORK between Regions_records and Nomenclatures_other\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_records.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:RegionRecord { id: row.ID})\n",
    "        MATCH (c:Nomenclature { id: row.Original_framework })\n",
    "        MERGE (a)-[:ORIGINAL_FRAMEWORK]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"ORIGINAL_FRAMEWORK\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 38 relationships of type PART_OF\n",
      "Added 74 relationships of type PART_OF\n"
     ]
    }
   ],
   "source": [
    "### Add Hierarchical relations between regions\n",
    "# RAT:\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_hierarchy_waxholm.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BrainRegion { id: row.ID})\n",
    "        MATCH (c:BrainRegion { id: row.Part_of })\n",
    "        MERGE (a)-[:PART_OF]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"PART_OF\", session)\n",
    "    \n",
    "# MOUSE:\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_hierarchy_amba.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BrainRegion { id: row.ID})\n",
    "        MATCH (c:BrainRegion { id: row.Part_of })\n",
    "        MERGE (a)-[:PART_OF]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"PART_OF\", session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOURCES RELATIONSHIPS\n",
    "\n",
    "def get_count_of_relationship(rel_label, fromLabel, toLabel, session):\n",
    "    q = \"MATCH (:%s)-[r:%s]-(:%s) RETURN count(*)\" % (fromLabel, rel_label, toLabel)\n",
    "    res = session.run(q)\n",
    "    print(\"Added\", res.value()[0], \"relationships of type\", fromLabel, rel_label, toLabel)\n",
    "\n",
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/sources\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 245 relationships of type Source COLLECTED_FROM SourceOrigin\n"
     ]
    }
   ],
   "source": [
    "# Relationship COLLECTED_FROM between Source and SourceOrigin\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"sources.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Source { id: row.ID})\n",
    "        MATCH (c:SourceOrigin { id: row.Source_origin })\n",
    "        MERGE (a)-[:COLLECTED_FROM]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"COLLECTED_FROM\", \"Source\", \"SourceOrigin\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2134 relationships of type ConsideredPaper COLLECTED_FROM SourceOrigin\n"
     ]
    }
   ],
   "source": [
    "# Relationship COLLECTED_FROM between ConsideredPaper and SourceOrigin\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"considered_papers.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:ConsideredPaper { id: row.ID})\n",
    "        MATCH (c:SourceOrigin { id: row.Journal })\n",
    "        MERGE (a)-[:COLLECTED_FROM]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"COLLECTED_FROM\", \"ConsideredPaper\", \"SourceOrigin\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUBJECT RELATIONSHIPS\n",
    "\n",
    "def get_count_of_relationship(label, session):\n",
    "    q = \"MATCH ()-[r:%s]-() RETURN count(*)\" %label\n",
    "    res = session.run(q)\n",
    "    print(\"Added\", res.value()[0], \"relationships of type\", label)\n",
    "\n",
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/subjects\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1006 relationships of type SPECIE\n"
     ]
    }
   ],
   "source": [
    "# Relationship SPECIE between Specimen and Specie\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_specimen.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Specimen { id: row.SpecimenId})\n",
    "        MATCH (c:Specie { id: row.Species })\n",
    "        MERGE (a)-[:SPECIE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"SPECIE\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 888 relationships of type STRAIN\n"
     ]
    }
   ],
   "source": [
    "# Relationship STRAIN between Specimen and Strain\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_specimen.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Specimen { id: row.SpecimenId})\n",
    "        MATCH (c:Strain { id: row.Strain })\n",
    "        MERGE (a)-[:STRAIN]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"STRAIN\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 240 relationships of type SUBSTRAIN\n"
     ]
    }
   ],
   "source": [
    "# Relationship SUBSTRAIN between Specimen and Specie\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_specimen.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Specimen { id: row.SpecimenId})\n",
    "        MATCH (c:Substrain { id: row.Substrain })\n",
    "        MERGE (a)-[:SUBSTRAIN]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"SUBSTRAIN\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 78 relationships of type TRANSGENIC_LINE\n"
     ]
    }
   ],
   "source": [
    "# Relationship TRANSGENIC_LINE between Specimen and TransgenicLine\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_specimen.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Specimen { id: row.SpecimenId})\n",
    "        MATCH (c:TransgenicLine { id: row.Transgenic_line_name })\n",
    "        MERGE (a)-[:TRANSGENIC_LINE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"TRANSGENIC_LINE\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 796 relationships of type SEX\n"
     ]
    }
   ],
   "source": [
    "# Relationship SEX between Specimen and Sex\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_specimen.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Specimen { id: row.SpecimenId})\n",
    "        MATCH (c:Sex { id: row.Sex })\n",
    "        MERGE (a)-[:SEX]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"SEX\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 796 relationships of type AGE_CATEGORY\n"
     ]
    }
   ],
   "source": [
    "# Relationship AGE_CATEGORY between Specimen and AgeCategory\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"derived_ddr_specimen.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Specimen { id: row.SpecimenId})\n",
    "        MATCH (c:AgeCategory { id: row.Sex })\n",
    "        MERGE (a)-[:AGE_CATEGORY]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"AGE_CATEGORY\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 48 relationships of type FROM_SPECIE\n"
     ]
    }
   ],
   "source": [
    "# Relationship FROM_SPECIE between Strain and Specie\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"strains.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:Strain { id: row.ID})\n",
    "        MATCH (c:Specie { id: row.Species })\n",
    "        MERGE (a)-[:FROM_SPECIE]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"FROM_SPECIE\", session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTENDED RELATIONSHIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 570 relationships of type CELLS_IN_REGION\n"
     ]
    }
   ],
   "source": [
    "# Relationship CELLS_IN_REGION between BrainRegion and Cell\n",
    "\n",
    "query=\"\"\"\n",
    "        MATCH (b:BrainRegion)<-[:PRIMARY_REGION]-(r:RegionRecord)<-[:REGION_RECORD]-(d)<-[:DATA_TYPE]-(:Analysis)-[:CELL_TYPE_PUTATIVE]->(c:CellType)\n",
    "        MERGE (b)-[:CELLS_IN_REGION]->(c)\n",
    "    \"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"CELLS_IN_REGION\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 176 relationships of type REGION_SPECIE\n"
     ]
    }
   ],
   "source": [
    "# Relationship REGION_SPECIE between BrainRegion and Specie\n",
    "query=\"\"\"\n",
    "        MATCH (a:BrainRegion)-[:NAMING]->(b:Nomenclature)-[:NOMENCLATURE_SPECIE]->(c:Specie)\n",
    "        MERGE (a)-[:REGION_SPECIE]->(c)\n",
    "    \"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"REGION_SPECIE\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 218 relationships of type OBSERVED_IN\n"
     ]
    }
   ],
   "source": [
    "# Relationship OBSERVED_IN from RegionZone to BrainRegion\n",
    "query=\"\"\"\n",
    "        MATCH (a:BrainRegion)<-[x]-(b:RegionRecord)<-[:REGION_RECORD]-(c)-[:REGION_ZONE]->(d:RegionZone)\n",
    "        MERGE (a)<-[:OBSERVED_IN]-(d)\n",
    "    \"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"OBSERVED_IN\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 40 relationships of type OBSERVED_CELL_REGION\n"
     ]
    }
   ],
   "source": [
    "# Relationship OBSERVED_CELL_REGION from CellType to CellularRegion\n",
    "\n",
    "query=\"\"\"\n",
    "        MATCH (a:CellType)<-[:CELL_TYPE_PUTATIVE]-(b:Analysis)-[:DATA_TYPE]-(c)-[:CELLULAR_TARGET_REGION]->(d:CellularRegion) \n",
    "        MERGE (a)-[:OBSERVED_CELL_REGION]->(d)\n",
    "    \"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    get_count_of_relationship(\"OBSERVED_CELL_REGION\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 270 relationships of type CONNECTS_TO\n",
      "Added 300 relationships of type RELATES_TO\n"
     ]
    }
   ],
   "source": [
    "# REGION CONNECTIVITY FROM BAMS\n",
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/regions\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")\n",
    "\n",
    "# Relationship CONNECTS_TO between BamsRegion and BamsRegion\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_connectivity.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BamsRegion { id: row.bams_id_from})\n",
    "        MATCH (c:BamsRegion { id: row.bams_id_to})\n",
    "        MERGE (a)-[:CONNECTS_TO]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "rel_query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BamsRegion {id: row.bams_id_from})-[r:CONNECTS_TO]->(b:BamsRegion { id: row.bams_id_to})\n",
    "        SET r.strength = row.strength\n",
    "        SET r.technique = row.technique\n",
    "        SET r.description = row.description\n",
    "        SET r.reference = row.reference\n",
    "        SET r.bamsFromId = row.bams_id_from\n",
    "        SET r.bamsToId = row.bams_id_to\n",
    "\"\"\" % csv_file_path\n",
    "\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"bams2_mapping_regions.csv\")\n",
    "mapping_query = \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BamsRegion { id: row.bams_id})\n",
    "        MATCH (c:BrainRegion { id: row.bg_id})\n",
    "        MERGE (a)-[:RELATES_TO]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "mapping_rel_query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BamsRegion {id: row.bams_id})-[r:RELATES_TO]->(b:BrainRegion {id: row.bg_id})\n",
    "        SET r.relationType = row.relation_type\n",
    "\"\"\" % csv_file_path\n",
    "\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    session.run(rel_query)\n",
    "    get_count_of_relationship(\"CONNECTS_TO\", session)\n",
    "    session.run(mapping_query)\n",
    "    session.run(mapping_rel_query)\n",
    "    get_count_of_relationship(\"RELATES_TO\", session)\n",
    "\n",
    "    #TODO Maybe add relation on BrainRegion-[Connects_To]-> BamsRegion and [Connects_From]\n",
    "    # and in website derive it trough BAMSRegion-:RELATES_TO-> BrainRegion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGION CONNECTIVITY OLD\n",
    "def get_csv_path(csv_file):\n",
    "    path_all_csv = os.path.realpath(\"Data/csvs/basal_ganglia/regions\")\n",
    "    return os.path.join(path_all_csv, csv_file).replace(\"\\\\\",\"/\")\n",
    "\n",
    "# Relationship CONNECTS_TO between BrainRegion and BrainRegion\n",
    "csv_file_path = \"file:///%s\" % get_csv_path(\"region_connectivity.csv\")\n",
    "query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BrainRegion { id: row.bg_id_from})\n",
    "        MATCH (c:BrainRegion { id: row.bg_id_to})\n",
    "        MERGE (a)-[:CONNECTS_TO]->(c)\n",
    "    \"\"\" % csv_file_path\n",
    "\n",
    "rel_query=\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"%s\" AS row\n",
    "        MATCH (a:BrainRegion {id: row.bg_id_from})-[r:CONNECTS_TO]->(b:BrainRegion { id: row.bg_id_to})\n",
    "        SET r.strength = row.strength\n",
    "        SET r.technique = row.technique\n",
    "        SET r.description = row.description\n",
    "        SET r.reference = row.reference\n",
    "        SET r.bamsFromId = row.bams_id_from\n",
    "        SET r.bamsToId = row.bams_id_to\n",
    "\"\"\" % csv_file_path\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(query)\n",
    "    session.run(rel_query)\n",
    "    get_count_of_relationship(\"CONNECTS_TO\", session)\n",
    "\n",
    "    #TODO Maybe add relation on BrainRegion-[Connects_To]-> BamsRegion and [Connects_From]\n",
    "    # and in website derive it trough BAMSRegion-:RELATES_TO-> BrainRegion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitf3fd17b590db4dcf8c20f5f3f0742f86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
